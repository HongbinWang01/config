a1.sources = r1 r2 nr1 nr2
a1.sinks = k1 k2 k3 k31 k32 k4 k5 k21 k22 k23 nk1 k8 k9 k91 k92 k94
a1.channels = c1 c2 c3 c4 c5 nc1 c9 c10 c11 c12
# Describe/configure the source
# avro
a1.sources.r1.type = avro
a1.sources.r1.port = 8349
a1.sources.r1.bind = 10.46.12.123
a1.sources.r1.batchSize = 100
a1.sources.r1.threads = 100
a1.sources.r1.selector.type=multiplexing
a1.sources.r1.selector.header=loggerName
a1.sources.r1.selector.mapping.kingdeehit.PATIENT.BUSSINESS=c1
a1.sources.r1.selector.mapping.kingdeehit.BUSINESS_REPORTING=c1
a1.sources.r1.selector.mapping.kingdeehit.HEALTHAD=c5
a1.sources.r1.selector.mapping.kingdeehit.PAGE_OPERATING=c4
a1.sources.r1.selector.mapping.kingdeehit.HIS-SERVICE=c2
a1.sources.r1.selector.mapping.kingdeehit.HTTP_SERVICE=c2
a1.sources.r1.selector.mapping.kingdeehit.API.HIS-SERVICE=c2
a1.sources.r1.selector.mapping.kingdeehit.API.Alipay=c3
a1.sources.r1.selector.mapping.kingdeehit.API.Wechat=c3
a1.sources.r1.selector.mapping.kingdeehit.DTR_MGR_LOGS=c9
a1.sources.r1.selector.mapping.kingdeehit.MWP_MOBILE_MONITOR_LOGS=c9
a1.sources.r1.selector.mapping.kingdeehit.MWP_DOCUMENT_DOWNLOAD_LOGS=c9
a1.sources.r1.selector.mapping.kingdeehit.MWP_CLOUD_LOGS=c10
a1.sources.r1.selector.mapping.kingdeehit.VISITAPP_LOGS=c11
a1.sources.r1.selector.mapping.kingdeehit.API.OPEN=c2

a1.sources.r1.interceptors=i1
a1.sources.r1.interceptors.i1.type=com.kingdeehit.bigdata.flume.interceptor.TenantIdInterceptor$Builder
a1.sources.r1.selector.default=c3
a1.sources.r2.type = avro
a1.sources.r2.port = 8349
a1.sources.r2.bind = 127.0.0.1
a1.sources.r2.batchSize = 100
a1.sources.r2.threads = 100
a1.sources.r2.selector.type=multiplexing
a1.sources.r2.selector.header=loggerName
a1.sources.r2.selector.mapping.kingdeehit.PATIENT.BUSSINESS=c1
a1.sources.r2.selector.mapping.kingdeehit.BUSINESS_REPORTING=c1
a1.sources.r2.selector.mapping.kingdeehit.HEALTHAD=c5
a1.sources.r2.selector.mapping.kingdeehit.PAGE_OPERATING=c4
a1.sources.r2.selector.mapping.kingdeehit.HIS-SERVICE=c2
a1.sources.r2.selector.mapping.kingdeehit.HTTP_SERVICE=c2
a1.sources.r2.selector.mapping.kingdeehit.API.HIS-SERVICE=c2
a1.sources.r2.selector.mapping.kingdeehit.API.Alipay=c3
a1.sources.r2.selector.mapping.kingdeehit.API.Wechat=c3
a1.sources.r2.selector.mapping.kingdeehit.DTR_MGR_LOGS=c9
a1.sources.r2.selector.mapping.kingdeehit.MWP_MOBILE_MONITOR_LOGS=c9
a1.sources.r2.selector.mapping.kingdeehit.MWP_DOCUMENT_DOWNLOAD_LOGS=c9
a1.sources.r2.selector.mapping.kingdeehit.MWP_CLOUD_LOGS=c10
a1.sources.r2.selector.mapping.kingdeehit.VISITAPP_LOGS=c11
a1.sources.r2.selector.mapping.kingdeehit.API.OPEN=c2


a1.sources.r2.interceptors=i2
a1.sources.r2.interceptors.i2.type=com.kingdeehit.bigdata.flume.interceptor.TenantIdInterceptor$Builder
a1.sources.r2.selector.default=c3
#nginx监听配置
a1.sources.nr1.type = exec
a1.sources.nr1.command = tail -F /usr/local/nginx/logs/access.log
a1.sources.nr1.shell = /bin/sh -c
a1.sources.nr2.type = exec
a1.sources.nr2.command = tail -F /usr/local/nginx/logs/access-pv.log
a1.sources.nr2.shell = /bin/sh -c
a1.channels.nc1.type = memory
a1.channels.nc1.capacity = 10000
a1.channels.nc1.keep-alive = 30
a1.channels.nc1.transactionCapacity = 1000
a1.channels.nc1.threads = 500
a1.sinks.nk1.type = org.apache.flume.sink.kafka.KafkaSink
# 这个地址是kafka的监听地址
a1.sinks.nk1.brokerList = 10.46.12.119:9092
# 注意这里的topic是zk的topic
a1.sinks.nk1.topic = nginx
a1.sinks.nk1.batchSize = 100
a1.sinks.nk1.requiredAcks =1
#a1.sinks.k1.type = logger
a1.sources.nr2.channels = nc1
a1.sources.nr1.channels = nc1
a1.sinks.nk1.channel = nc1
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.keep-alive = 30
a1.channels.c1.transactionCapacity = 1000
a1.channels.c1.threads = 500
a1.channels.c2.type = memory
a1.channels.c2.capacity = 100000
a1.channels.c2.keep-alive = 60
a1.channels.c2.transactionCapacity = 100
a1.channels.c2.threads = 500
a1.channels.c3.type = memory
a1.channels.c3.capacity = 10000
a1.channels.c3.keep-alive = 30
a1.channels.c3.transactionCapacity = 1000
a1.channels.c3.threads = 500
a1.channels.c4.type = memory
a1.channels.c4.capacity = 10000
a1.channels.c4.keep-alive = 30
a1.channels.c4.transactionCapacity = 1000
a1.channels.c4.threads = 500
a1.channels.c5.type = memory
a1.channels.c5.capacity = 10000
a1.channels.c5.keep-alive = 30
a1.channels.c5.transactionCapacity = 1000
a1.channels.c5.threads = 500

a1.channels.c8.type = memory
a1.channels.c8.capacity = 10000
a1.channels.c8.keep-alive = 30
a1.channels.c8.transactionCapacity = 1000

a1.channels.c9.type = memory
a1.channels.c9.capacity = 10000
a1.channels.c9.keep-alive = 30
a1.channels.c9.transactionCapacity = 1000

a1.channels.c10.type = memory
a1.channels.c10.capacity = 10000
a1.channels.c10.keep-alive = 30
a1.channels.c10.transactionCapacity = 1000

a1.channels.c11.type = memory
a1.channels.c11.capacity = 10000
a1.channels.c11.keep-alive = 30
a1.channels.c11.transactionCapacity = 1000

a1.channels.c12.type = memory
a1.channels.c12.capacity = 10000
a1.channels.c12.keep-alive = 30
a1.channels.c12.transactionCapacity = 1000

# Bind the source and sink to the channel
a1.sources.r1.channels = c1 c2 c3 c4 c5 c7 c8 c9 c10 c11 c12
a1.sources.r2.channels = c1 c2 c3 c4 c5 c7 c8 c9 c10 c11 c12
# Describe the sink
# kafka sink
# kafka sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.topic = mih-pat-app-logs
a1.sinks.k1.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.max.request.size = 8388608
a1.sinks.k1.kafka.producer.retries = 3
a1.sinks.k1.kafka.producer.linger.ms = 50
a1.sinks.k1.flumeBatchSize = 100
a1.sinks.k1.producer.type=async
a1.sinks.k1.channel = c1
a1.sinks.k2.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k2.kafka.topic = mih-his-api-logs
a1.sinks.k2.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k2.kafka.producer.acks = 0
a1.sinks.k2.kafka.producer.max.request.size = 83886080
a1.sinks.k2.kafka.producer.linger.ms = 50
a1.sinks.k2.flumeBatchSize = 100
a1.sinks.k2.producer.type=async
a1.sinks.k2.channel = c2

a1.sinks.k21.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k21.kafka.topic = mih-his-api-logs
a1.sinks.k21.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k21.kafka.producer.acks = 0
a1.sinks.k21.kafka.producer.max.request.size = 83886080
a1.sinks.k21.kafka.producer.linger.ms = 50
a1.sinks.k21.flumeBatchSize = 100
a1.sinks.k21.producer.type=async
a1.sinks.k21.channel = c2

a1.sinks.k22.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k22.kafka.topic = mih-his-api-logs
a1.sinks.k22.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k22.kafka.producer.acks = 0
a1.sinks.k22.kafka.producer.max.request.size = 83886080
a1.sinks.k22.kafka.producer.linger.ms = 50
a1.sinks.k22.flumeBatchSize = 100
a1.sinks.k22.producer.type=async
a1.sinks.k22.channel = c2

a1.sinks.k23.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k23.kafka.topic = mih-his-api-logs
a1.sinks.k23.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k23.kafka.producer.acks = 0
a1.sinks.k23.kafka.producer.max.request.size = 83886080
a1.sinks.k23.kafka.producer.linger.ms = 50
a1.sinks.k23.flumeBatchSize = 100
a1.sinks.k23.producer.type=async
a1.sinks.k23.channel = c2
a1.sinks.k3.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k3.kafka.topic = mih-system-logs
a1.sinks.k3.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k3.kafka.producer.acks = 1
a1.sinks.k3.kafka.producer.max.request.size = 8388608
a1.sinks.k3.kafka.producer.retries = 3
a1.sinks.k3.kafka.producer.linger.ms = 50
a1.sinks.k3.flumeBatchSize = 100
a1.sinks.k3.producer.type=async
a1.sinks.k3.channel = c3
a1.sinks.k31.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k31.kafka.topic = mih-system-logs
a1.sinks.k31.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k31.kafka.producer.acks = 1
a1.sinks.k31.kafka.producer.max.request.size = 8388608
a1.sinks.k31.kafka.producer.retries = 3
a1.sinks.k31.kafka.producer.linger.ms = 50
a1.sinks.k31.flumeBatchSize = 100
a1.sinks.k31.producer.type=async
a1.sinks.k31.channel = c3

a1.sinks.k32.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k32.kafka.topic = mih-system-logs
a1.sinks.k32.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k32.kafka.producer.acks = 1
a1.sinks.k32.kafka.producer.max.request.size = 8388608
a1.sinks.k32.kafka.producer.retries = 3
a1.sinks.k32.kafka.producer.linger.ms = 50
a1.sinks.k32.flumeBatchSize = 100
a1.sinks.k32.producer.type=async
a1.sinks.k32.channel = c3
a1.sinks.k4.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k4.kafka.topic = mih-pat-pv-logs
a1.sinks.k4.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k4.kafka.producer.acks = 1
a1.sinks.k4.kafka.producer.max.request.size = 8388608
a1.sinks.k4.kafka.producer.retries = 3
a1.sinks.k4.kafka.producer.linger.ms = 50
a1.sinks.k4.flumeBatchSize = 100
a1.sinks.k4.producer.type=async
a1.sinks.k4.channel = c4
a1.sinks.k5.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k5.kafka.topic = mih-health-ad-logs
a1.sinks.k5.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k5.kafka.producer.acks = 1
a1.sinks.k5.kafka.producer.max.request.size=8388608
a1.sinks.k5.kafka.producer.retries = 3
a1.sinks.k5.kafka.producer.linger.ms = 50
a1.sinks.k5.flumeBatchSize = 100
a1.sinks.k5.producer.type=async
a1.sinks.k5.channel = c5


a1.sinks.k8.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k8.kafka.topic = mih-cloud-app-logs
a1.sinks.k8.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k8.kafka.producer.acks = 1
a1.sinks.k8.kafka.producer.max.request.size=8388608
a1.sinks.k8.kafka.producer.retries = 3
a1.sinks.k8.kafka.producer.linger.ms = 50
a1.sinks.k8.flumeBatchSize = 100
a1.sinks.k8.producer.type=async
a1.sinks.k8.channel = c8


a1.sinks.k9.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k9.kafka.topic = mwp-cloud-logs
a1.sinks.k9.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k9.kafka.producer.acks = 1
a1.sinks.k9.kafka.producer.max.request.size=8388608
a1.sinks.k9.kafka.producer.retries = 3
a1.sinks.k9.flumeBatchSize = 100
a1.sinks.k9.producer.type=async
a1.sinks.k9.channel = c10


a1.sinks.k91.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k91.kafka.topic = mwp-dtr-web-logs
a1.sinks.k91.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k91.kafka.producer.acks = 1
a1.sinks.k91.kafka.producer.max.request.size=8388608
a1.sinks.k91.kafka.producer.retries = 3
a1.sinks.k91.flumeBatchSize = 100
a1.sinks.k91.producer.type=async
a1.sinks.k91.channel = c9

a1.sinks.k92.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k92.kafka.topic = mwp-dtr-web-logs
a1.sinks.k92.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k92.kafka.producer.acks = 1
a1.sinks.k92.kafka.producer.max.request.size=8388608
a1.sinks.k92.kafka.producer.retries = 3
a1.sinks.k92.flumeBatchSize = 100
a1.sinks.k92.producer.type=async
a1.sinks.k92.channel = c9


a1.sinks.k94.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k94.kafka.topic = mwp-visitapp
a1.sinks.k94.kafka.bootstrap.servers = 10.46.12.119:9092
a1.sinks.k94.kafka.producer.acks = 1
a1.sinks.k94.kafka.producer.max.request.size=8388608
a1.sinks.k94.kafka.producer.retries = 3
a1.sinks.k94.flumeBatchSize = 1
a1.sinks.k94.producer.type=async
a1.sinks.k94.channel = c11
